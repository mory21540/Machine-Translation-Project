{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1067156,"sourceType":"datasetVersion","datasetId":592212}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-18T09:43:22.378692Z","iopub.execute_input":"2023-11-18T09:43:22.379013Z","iopub.status.idle":"2023-11-18T09:43:22.729871Z","shell.execute_reply.started":"2023-11-18T09:43:22.378988Z","shell.execute_reply":"2023-11-18T09:43:22.728978Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/language-translation-englishfrench/eng_-french.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Importation des librairies Python**","metadata":{}},{"cell_type":"code","source":"import collections\n\nimport re\nimport numpy as np\nimport pandas as pd\n\n\nimport tensorflow as tf\nfrom keras.models import Model, Sequential\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Model\nfrom keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional,Dropout\nfrom keras.layers import Embedding\nfrom keras.optimizers import Adam\nfrom keras.losses import sparse_categorical_crossentropy","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:58:37.571567Z","iopub.execute_input":"2023-11-18T09:58:37.572206Z","iopub.status.idle":"2023-11-18T09:58:37.578554Z","shell.execute_reply.started":"2023-11-18T09:58:37.572172Z","shell.execute_reply":"2023-11-18T09:58:37.577550Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n\n# Download the stopwords dataset (only need to do this once)\nnltk.download('stopwords')\n\n# Get the list of stopwords for a specific language, for example, English\nstop_words = set(stopwords.words('english'))\nimport string","metadata":{"execution":{"iopub.status.busy":"2023-11-18T10:59:19.813060Z","iopub.execute_input":"2023-11-18T10:59:19.813483Z","iopub.status.idle":"2023-11-18T10:59:20.840377Z","shell.execute_reply.started":"2023-11-18T10:59:19.813451Z","shell.execute_reply":"2023-11-18T10:59:20.839521Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Importation du dataset**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/language-translation-englishfrench/eng_-french.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:43:45.927840Z","iopub.execute_input":"2023-11-18T09:43:45.928221Z","iopub.status.idle":"2023-11-18T09:43:46.429836Z","shell.execute_reply.started":"2023-11-18T09:43:45.928169Z","shell.execute_reply":"2023-11-18T09:43:46.428693Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  English words/sentences French words/sentences\n0                     Hi.                 Salut!\n1                    Run!                Cours !\n2                    Run!               Courez !\n3                    Who?                  Qui ?\n4                    Wow!             Ça alors !","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English words/sentences</th>\n      <th>French words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"eng = df['English words/sentences']\nfr = df['French words/sentences']","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:43:46.431518Z","iopub.execute_input":"2023-11-18T09:43:46.431880Z","iopub.status.idle":"2023-11-18T09:43:46.438116Z","shell.execute_reply.started":"2023-11-18T09:43:46.431847Z","shell.execute_reply":"2023-11-18T09:43:46.436823Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for sample_i in range(2,10):\n    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, eng[sample_i]))\n    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, fr[sample_i]))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:43:46.441208Z","iopub.execute_input":"2023-11-18T09:43:46.441564Z","iopub.status.idle":"2023-11-18T09:43:46.452496Z","shell.execute_reply.started":"2023-11-18T09:43:46.441531Z","shell.execute_reply":"2023-11-18T09:43:46.451554Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"small_vocab_en Line 3:  Run!\nsmall_vocab_fr Line 3:  Courez !\nsmall_vocab_en Line 4:  Who?\nsmall_vocab_fr Line 4:  Qui ?\nsmall_vocab_en Line 5:  Wow!\nsmall_vocab_fr Line 5:  Ça alors !\nsmall_vocab_en Line 6:  Fire!\nsmall_vocab_fr Line 6:  Au feu !\nsmall_vocab_en Line 7:  Help!\nsmall_vocab_fr Line 7:  À l'aide !\nsmall_vocab_en Line 8:  Jump.\nsmall_vocab_fr Line 8:  Saute.\nsmall_vocab_en Line 9:  Stop!\nsmall_vocab_fr Line 9:  Ça suffit !\nsmall_vocab_en Line 10:  Stop!\nsmall_vocab_fr Line 10:  Stop !\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Mettre en place une liste de vocabulaires des mots pour chaque types de dataset**","metadata":{}},{"cell_type":"code","source":"english_words_counter = collections.Counter([word for sentence in eng for word in sentence.split()])\nfrench_words_counter = collections.Counter([word for sentence in fr for word in sentence.split()])\n\nprint('{} English words.'.format(len([word for sentence in eng for word in sentence.split()])))\nprint('{} unique English words.'.format(len(english_words_counter)))\nprint('10 Most common words in the English dataset:')\nprint('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\nprint()\nprint('{} French words.'.format(len([word for sentence in fr for word in sentence.split()])))\nprint('{} unique French words.'.format(len(french_words_counter)))\nprint('10 Most common words in the French dataset:')\nprint('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:43:46.453915Z","iopub.execute_input":"2023-11-18T09:43:46.454262Z","iopub.status.idle":"2023-11-18T09:43:47.494019Z","shell.execute_reply.started":"2023-11-18T09:43:46.454230Z","shell.execute_reply":"2023-11-18T09:43:47.493077Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1082098 English words.\n27393 unique English words.\n10 Most common words in the English dataset:\n\"I\" \"to\" \"you\" \"the\" \"a\" \"is\" \"Tom\" \"of\" \"in\" \"have\"\n\n1177832 French words.\n44918 unique French words.\n10 Most common words in the French dataset:\n\"de\" \"Je\" \"?\" \"pas\" \"que\" \"à\" \"ne\" \"la\" \"le\" \"Il\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Prétraitement des données**","metadata":{}},{"cell_type":"code","source":"def tokenize(x):\n    \"\"\"\n    Tokenize x\n    :param x: List of sentences/strings to be tokenized\n    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n    \"\"\"\n    # TODO: Implement\n\n    x_tk = Tokenizer()\n    x_tk.fit_on_texts(x)\n    return x_tk.texts_to_sequences(x), x_tk","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:43:47.495246Z","iopub.execute_input":"2023-11-18T09:43:47.495540Z","iopub.status.idle":"2023-11-18T09:43:47.500970Z","shell.execute_reply.started":"2023-11-18T09:43:47.495514Z","shell.execute_reply":"2023-11-18T09:43:47.500033Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def pad(x, length=None):\n    \"\"\"\n    Pad x\n    :param x: List of sequences.\n    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n    :return: Padded numpy array of sequences\n    \"\"\"\n    if length is None:\n        # Find the length of the longest sequence/sentence\n        length = max([len(seq) for seq in x])\n\n    return pad_sequences(sequences=x, maxlen=55, padding='post')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:51:36.226257Z","iopub.execute_input":"2023-11-18T12:51:36.227115Z","iopub.status.idle":"2023-11-18T12:51:36.232209Z","shell.execute_reply.started":"2023-11-18T12:51:36.227079Z","shell.execute_reply":"2023-11-18T12:51:36.231312Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"def preprocess(x, y):\n   \n    preprocess_x, x_tk = tokenize(x)\n    preprocess_y, y_tk = tokenize(y)\n\n    preprocess_x = pad(preprocess_x)\n    preprocess_y = pad(preprocess_y)\n\n    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n\n    return preprocess_x, preprocess_y, x_tk, y_tk\n\npreproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(eng, fr)\n\nmax_english_sequence_length = preproc_english_sentences.shape[1]\nmax_french_sequence_length = preproc_french_sentences.shape[1]\nenglish_vocab_size = len(english_tokenizer.word_index)\nfrench_vocab_size = len(french_tokenizer.word_index)\n\nprint('Data Preprocessed')\nprint(\"Max English sentence length:\", max_english_sequence_length)\nprint(\"Max French sentence length:\", max_french_sequence_length)\nprint(\"English vocabulary size:\", english_vocab_size)\nprint(\"French vocabulary size:\", french_vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:51:37.192183Z","iopub.execute_input":"2023-11-18T12:51:37.192517Z","iopub.status.idle":"2023-11-18T12:51:49.448985Z","shell.execute_reply.started":"2023-11-18T12:51:37.192492Z","shell.execute_reply":"2023-11-18T12:51:49.448070Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"Data Preprocessed\nMax English sentence length: 55\nMax French sentence length: 55\nEnglish vocabulary size: 14531\nFrench vocabulary size: 30660\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Mise en place de la fonction de correspondance Identifiant du mot vers le mot**","metadata":{}},{"cell_type":"code","source":"def logits_to_text(logits, tokenizer):\n    \"\"\"\n    Turn logits from a neural network into text using the tokenizer\n    :param logits: Logits from a neural network\n    :param tokenizer: Keras Tokenizer fit on the labels\n    :return: String that represents the text of the logits\n    \"\"\"\n    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n    index_to_words[0] = '<PAD>'\n\n    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:51:49.451080Z","iopub.execute_input":"2023-11-18T12:51:49.451678Z","iopub.status.idle":"2023-11-18T12:51:49.457337Z","shell.execute_reply.started":"2023-11-18T12:51:49.451641Z","shell.execute_reply":"2023-11-18T12:51:49.456408Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"**Modélisation de notre modèle de Deep Learning pour la traduction**","metadata":{}},{"cell_type":"code","source":"def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n    \n    learning_rate = 0.003\n    \n    # Build the layers\n    model = Sequential()\n    model.add(Embedding(french_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n    model.add(Bidirectional(GRU(256, return_sequences=True)))\n    model.add(TimeDistributed(Dense(1024, activation='relu')))\n    model.add(Dropout(0.5))\n    model.add(TimeDistributed(Dense(english_vocab_size, activation='softmax'))) \n\n    # Compile model\n    model.compile(loss=sparse_categorical_crossentropy,\n                  optimizer=Adam(learning_rate),\n                  metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:51:49.458786Z","iopub.execute_input":"2023-11-18T12:51:49.459538Z","iopub.status.idle":"2023-11-18T12:51:49.468441Z","shell.execute_reply.started":"2023-11-18T12:51:49.459510Z","shell.execute_reply":"2023-11-18T12:51:49.467650Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"**Entraiment et Evaluation du modèle**","metadata":{}},{"cell_type":"code","source":"# Reshape the input\ntmp_x = pad(preproc_french_sentences, preproc_french_sentences.shape[1])\ntmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n\n# Train \nmodel = bd_model(\n    tmp_x.shape,\n    preproc_english_sentences.shape[1],\n    len(english_tokenizer.word_index)+1,\n    len(french_tokenizer.word_index)+1)\n\nmodel.summary()\n\nmodel.fit(tmp_x, preproc_english_sentences, batch_size=256, epochs=5, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:54:49.291626Z","iopub.execute_input":"2023-11-18T12:54:49.292092Z","iopub.status.idle":"2023-11-18T13:22:50.577172Z","shell.execute_reply.started":"2023-11-18T12:54:49.292057Z","shell.execute_reply":"2023-11-18T13:22:50.576254Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Model: \"sequential_11\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_12 (Embedding)    (None, 55, 256)           7849216   \n                                                                 \n bidirectional_11 (Bidirect  (None, 55, 512)           789504    \n ional)                                                          \n                                                                 \n time_distributed_22 (TimeD  (None, 55, 1024)          525312    \n istributed)                                                     \n                                                                 \n dropout_10 (Dropout)        (None, 55, 1024)          0         \n                                                                 \n time_distributed_23 (TimeD  (None, 55, 14532)         14895300  \n istributed)                                                     \n                                                                 \n=================================================================\nTotal params: 24059332 (91.78 MB)\nTrainable params: 24059332 (91.78 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\nEpoch 1/5\n549/549 [==============================] - 336s 605ms/step - loss: 0.5640 - accuracy: 0.9220 - val_loss: 1.0320 - val_accuracy: 0.8607\nEpoch 2/5\n549/549 [==============================] - 336s 611ms/step - loss: 0.3292 - accuracy: 0.9417 - val_loss: 0.8560 - val_accuracy: 0.8719\nEpoch 3/5\n549/549 [==============================] - 341s 621ms/step - loss: 0.2493 - accuracy: 0.9496 - val_loss: 0.8242 - val_accuracy: 0.8755\nEpoch 4/5\n549/549 [==============================] - 335s 611ms/step - loss: 0.2055 - accuracy: 0.9548 - val_loss: 0.8594 - val_accuracy: 0.8771\nEpoch 5/5\n549/549 [==============================] - 331s 603ms/step - loss: 0.1774 - accuracy: 0.9588 - val_loss: 0.8663 - val_accuracy: 0.8783\n","output_type":"stream"},{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7cf2c69828c0>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Fonction de Traduction**","metadata":{}},{"cell_type":"code","source":"  i=200\n\n\n  print(\"Prediction:\")\n  print(logits_to_text(model.predict(tmp_x[[i]])[0], english_tokenizer))\n\n  print(\"\\nCorrect Translation:\")\n  print(eng[i])\n\n  print(\"\\nOriginal text:\")\n  print(fr[i])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T13:28:24.166113Z","iopub.execute_input":"2023-11-18T13:28:24.166854Z","iopub.status.idle":"2023-11-18T13:28:24.233936Z","shell.execute_reply.started":"2023-11-18T13:28:24.166821Z","shell.execute_reply":"2023-11-18T13:28:24.233103Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Prediction:\n1/1 [==============================] - 0s 21ms/step\ntake it <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n\nCorrect Translation:\nTake it.\n\nOriginal text:\nPrends-le !\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}